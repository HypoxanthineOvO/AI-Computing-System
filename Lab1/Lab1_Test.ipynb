{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch # As Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer:  \n",
    "    def __init__(self, input_channels: int, output_channels: int, kernel_size: int, stride: int, padding: int):   \n",
    "        self.input_channels: int = input_channels\n",
    "        self.output_channels: int = output_channels\n",
    "        self.kernel_size: int = kernel_size  \n",
    "        self.stride: int = stride\n",
    "        self.padding: int = padding \n",
    "  \n",
    "    def forward(self, x: np.ndarray, weight: np.ndarray):  \n",
    "        \"\"\"    \n",
    "        input x: (N, C, H, W) [batchsize, input channels, x_height, x_width]\n",
    "        input w: (K, C, R, S) [output channels, input channels, w_height, w_width] \n",
    "        output: (N, K, P, Q) [batchsize, output channels, output_height, output_width]\n",
    "        \"\"\"  \n",
    "        assert x.shape[1] == weight.shape[1], \"x and weight have different input channels!\"\n",
    "        N, C, H, W = x.shape\n",
    "        K, C, R, S = weight.shape\n",
    "        \n",
    "        \n",
    "        assert C == self.input_channels, \"Invalid Input Channels!\"\n",
    "        assert K == self.output_channels, \"Invalid Output Channels!\"\n",
    "         \n",
    "        # Complete padding operation\n",
    "        \n",
    "        # x_padded = np.zeros([N, C, H + 2 * self.padding, W + 2 * self.padding])\n",
    "        # if (self.padding):\n",
    "        #     x_padded[:, :, self.padding: -self.padding, self.padding : -self.padding] = x\n",
    "        x_padded = np.pad(\n",
    "            x, ((0, 0), (0, 0), (self.padding, self.padding), (self.padding, self.padding)), \n",
    "            mode='constant'\n",
    "        )\n",
    "        # Compute output size using self.padding and self.stride\n",
    "        ## P = floor((H + 2 * padding_x - R) / stride) + 1\n",
    "        ## Q = floor((W + 2 * padding_y - S) / stride) + 1\n",
    "        P: np.ndarray = np.floor((H + 2 * self.padding - R) / self.stride) + 1\n",
    "        Q: np.ndarray = np.floor((W + 2 * self.padding - S) / self.stride) + 1\n",
    "        P, Q = P.astype(np.int32).item(), Q.astype(np.int32).item()\n",
    "        \n",
    "        output = np.zeros([N, K, P, Q])\n",
    "        # complete convolution operation\n",
    "        for batch_id in range(N):\n",
    "            for output_channel in range(K):\n",
    "                feature = np.zeros([P, Q])\n",
    "                for input_channel in range(C):\n",
    "                    # Each Single channel\n",
    "                    x_processed = x_padded[batch_id, input_channel]\n",
    "                    w_processed = weight[output_channel, input_channel]\n",
    "                    for i in range(0, H + 2 * self.padding - R + 1, self.stride):\n",
    "                        for j in range(0, W + 2 * self.padding - S + 1, self.stride):\n",
    "                            x_partial = x_processed[i: i + R, j: j + S]\n",
    "                            #height_partial, width_partial = x_partial.shape\n",
    "                            #w_partial = w_processed[:height_partial, :width_partial]\n",
    "                            #feature_propossed = np.sum(x_partial * w_partial)\n",
    "                            feature_propossed = np.sum(x_partial * w_processed)\n",
    "                            feature[i // self.stride, j // self.stride] += feature_propossed\n",
    "                output[batch_id, output_channel] = feature\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 4, 28, 28) torch.Size([5, 4, 28, 28])\n",
      "tensor(1.2151e-10, dtype=torch.float64, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Test Convolution\n",
    "conv = ConvLayer(3, 4, 5, 1, 0)\n",
    "conv_ref = torch.nn.Conv2d(3, 4, 5, 1, 0, bias = False)\n",
    "\n",
    "# batch_size: 5; input_channels: 3; output_channels: 6\n",
    "# x_w, x_h: 10, 10; kernel_w, kernel_h: 3, 3\n",
    "# output_shape sould be: [5, 6, 10, 10]\n",
    "x = np.ones([5, 3, 32, 32], dtype = np.float32)\n",
    "x_torch = torch.tensor(x)\n",
    "w_torch = conv_ref.weight\n",
    "w = w_torch.detach().numpy()\n",
    "\n",
    "out = conv.forward(x, w)\n",
    "ref = conv_ref.forward(x_torch)\n",
    "\n",
    "print(out.shape, ref.shape)\n",
    "mse = torch.sum(torch.square(torch.tensor(out) - ref))\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Max Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPooling2D:  \n",
    "    def __init__(self, pool_size: tuple = (2, 2), stride: int = 2):  \n",
    "        self.pool_size: tuple = pool_size  \n",
    "        self.stride: int = stride  \n",
    "    def forward(self, x: np.ndarray):  \n",
    "        \"\"\"    \n",
    "        input x: (N, C, H, W) [batchsize, input channels, x_height, x_width]\n",
    "        output: (N, C, pooled_height, pooled_width)\n",
    "        \"\"\"  \n",
    "        N, C, H, W = x.shape\n",
    "        # compute output size using self.pool_size and self.stride\n",
    "        \n",
    "        pooled_height: np.ndarray = np.floor((H - self.pool_size[0]) / self.stride) + 1\n",
    "        pooled_width: np.ndarray = np.floor((W - self.pool_size[1]) / self.stride) + 1\n",
    "        pooled_height, pooled_width = pooled_height.astype(np.int32).item(), pooled_width.astype(np.int32).item()\n",
    "  \n",
    "        output = np.zeros((N, C, pooled_height, pooled_width))\n",
    "        # complete max-pooling operation\n",
    "        for batch_id in range(N):\n",
    "            for input_channel  in range(C):\n",
    "                feature = np.zeros([pooled_height, pooled_width])\n",
    "                # Single Image\n",
    "                x_processed = x[batch_id, input_channel]\n",
    "                i_cnt, j_cnt = 0, 0\n",
    "                for i in range(0, H, self.stride):\n",
    "                    for j in range(0, W, self.stride):\n",
    "                        feature_processed = np.max(x_processed[i: i+self.pool_size[0], j: j + self.pool_size[1]])\n",
    "                        feature[i_cnt, j_cnt] = feature_processed\n",
    "                        j_cnt += 1\n",
    "                    i_cnt += 1\n",
    "                    j_cnt = 0\n",
    "                output[batch_id, input_channel] = feature\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3, 5, 5) torch.Size([5, 3, 5, 5])\n",
      "tensor(0., dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Test Max Pooling\n",
    "pooling = MaxPooling2D()\n",
    "pooling_ref = torch.nn.MaxPool2d(kernel_size = (2, 2), stride = 2)\n",
    "\n",
    "\n",
    "out = pooling.forward(x)\n",
    "ref = pooling_ref.forward(x_torch)\n",
    "print(out.shape, ref.shape)\n",
    "mse = torch.sum(torch.square(torch.tensor(out) - ref))\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fclayer():\n",
    "    def __init__(self, in_features: int, out_features: int):\n",
    "        self.in_features: int = in_features\n",
    "        self.out_features: int = out_features\n",
    "        \n",
    "    def forward(self, x: np.ndarray, weight: np.ndarray):\n",
    "        # complete forward propagation of fully-connected layer\n",
    "        \n",
    "        assert self.in_features == x.shape[-1]\n",
    "        assert self.in_features == weight.shape[-1]\n",
    "        assert self.out_features == weight.shape[0]\n",
    "        output = np.dot(x, weight.T)\n",
    "        return output  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3) torch.Size([5, 3])\n",
      "tensor(7.8881e-14, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mlp = fclayer(64, 3)\n",
    "mlp_ref = torch.nn.Linear(64, 3, bias = False)\n",
    "\n",
    "inp = np.random.randn(5, 64).astype(np.float32)\n",
    "inp_torch = torch.tensor(inp)\n",
    "w = mlp_ref.weight.detach().numpy()\n",
    "\n",
    "out = mlp.forward(inp, w)\n",
    "ref = mlp_ref.forward(inp_torch)\n",
    "\n",
    "print(out.shape, ref.shape)\n",
    "mse = torch.sum(torch.square(torch.tensor(out) - ref))\n",
    "print(mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
